import re
import nltk
import spacy
from typing import List, Dict
from collections import Counter

# Download necessÃ¡rio para NLTK
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

class NLPAnalyzer:
    """Classe para analisar problemas de PLN em texto transcrito"""
    
    def __init__(self):
        # Carregar modelo do spaCy para inglÃªs
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except OSError:
            print("âš ï¸ Modelo spaCy nÃ£o encontrado. Execute: python -m spacy download en_core_web_sm")
            self.nlp = None
        
        # DicionÃ¡rio de homÃ³fonos comuns em inglÃªs
        self.homophones = {
            'to': ['too', 'two'],
            'too': ['to', 'two'],
            'two': ['to', 'too'],
            'there': ['their', 'they\'re'],
            'their': ['there', 'they\'re'],
            'they\'re': ['there', 'their'],
            'your': ['you\'re'],
            'you\'re': ['your'],
            'its': ['it\'s'],
            'it\'s': ['its'],
            'hear': ['here'],
            'here': ['hear'],
            'write': ['right', 'rite'],
            'right': ['write', 'rite'],
            'rite': ['write', 'right'],
            'new': ['knew'],
            'knew': ['new'],
            'four': ['for', 'fore'],
            'for': ['four', 'fore'],
            'fore': ['four', 'for'],
            'eight': ['ate'],
            'ate': ['eight'],
            'one': ['won'],
            'won': ['one'],
            'sun': ['son'],
            'son': ['sun'],
            'flower': ['flour'],
            'flour': ['flower'],
            'break': ['brake'],
            'brake': ['break'],
            'pears': ['pairs'],
            'pairs': ['pears'],
            'pair': ['pear'],
            'pear': ['pair'],
            'sea': ['see'],
            'see': ['sea'],
            'meat': ['meet'],
            'meet': ['meat'],
            'peace': ['piece'],
            'piece': ['peace'],
            'no': ['know'],
            'know': ['no'],
            'by': ['buy', 'bye'],
            'buy': ['by', 'bye'],
            'bye': ['by', 'buy'],
            'read': ['red'],
            'red': ['read'],
            'tail': ['tale'],
            'tale': ['tail'],
            'mail': ['male'],
            'male': ['mail'],
            'sail': ['sale'],
            'sale': ['sail'],
            'wait': ['weight'],
            'weight': ['wait'],
            'weak': ['week'],
            'week': ['weak'],
            'steel': ['steal'],
            'steal': ['steel'],
            'bear': ['bare'],
            'bare': ['bear'],
            'fair': ['fare'],
            'fare': ['fair']
        }
        
        # Frases problemÃ¡ticas conhecidas para segmentaÃ§Ã£o
        self.segmentation_patterns = [
            r"let'?s eat \w+",
            r"come and eat \w+",
            r"time to eat \w+"
        ]
    
    def analyze_speech_text(self, text: str) -> Dict:
        """Analisa texto de fala para problemas de PLN"""
        problems = {
            'original_text': text,
            'homophones': self._find_homophones(text),
            'punctuation': self._check_punctuation_problems(text),
            'segmentation': self._check_segmentation(text)
        }
        return problems
    
    def display_detailed_analysis(self, problems: Dict):
        """Exibe anÃ¡lise detalhada dos problemas encontrados"""
        text = problems['original_text']
        
        print(f"\n{'='*60}")
        print(f"ðŸ“ TEXTO TRANSCRITO: '{text}'")
        print(f"{'='*60}")
        
        total_problems = 0
        
        # HomÃ³fonos com explicaÃ§Ã£o expandida
        if problems['homophones']:
            print("\nðŸ”„ PROBLEMA: AMBIGUIDADE LEXICAL (HOMÃ“FONOS)")
            print("â”" * 50)
            print("ðŸ“– EXPLICAÃ‡ÃƒO:")
            print("   HomÃ³fonos sÃ£o palavras com a mesma pronÃºncia, mas grafias e")
            print("   significados diferentes. O sistema de reconhecimento de fala pode")
            print("   transcrever a palavra incorreta, alterando completamente o sentido")
            print("   da frase. Este Ã© um problema crÃ­tico para PLN pois:")
            print("   â€¢ AnÃ¡lise semÃ¢ntica fica comprometida")
            print("   â€¢ Sistemas de traduÃ§Ã£o podem falhar")
            print("   â€¢ ClassificaÃ§Ã£o de texto produz resultados incorretos")
            print("   â€¢ AnÃ¡lise de sentimento pode ser invertida")
            print()
            print("ðŸ” HOMÃ“FONOS DETECTADOS:")
            for h in problems['homophones']:
                print(f"   âš ï¸  Palavra transcrita: '{h['word']}'")
                print(f"   ðŸ¤” PossÃ­veis confusÃµes: {', '.join(h['alternatives'])}")
                
                # Exemplos especÃ­ficos baseados na palavra
                if h['word'] in ['two', 'to', 'too']:
                    print("   ðŸ’¡ Exemplo de confusÃ£o:")
                    print("      'I have two apples' vs 'I want to go' vs 'It's too hot'")
                elif h['word'] in ['there', 'their', 'they\'re']:
                    print("   ðŸ’¡ Exemplo de confusÃ£o:")
                    print("      'There is a book' vs 'Their house' vs 'They're coming'")
                elif h['word'] in ['pairs', 'pears']:
                    print("   ðŸ’¡ Exemplo de confusÃ£o:")
                    print("      'Two pairs of shoes' vs 'Two pears from tree'")
                print()
                total_problems += 1
        
        # SegmentaÃ§Ã£o com explicaÃ§Ã£o expandida
        if problems['segmentation']['has_problems']:
            print("\nðŸ“– PROBLEMA: ERROS DE SEGMENTAÃ‡ÃƒO/PONTUAÃ‡ÃƒO")
            print("â”" * 50)
            print("ðŸ“– EXPLICAÃ‡ÃƒO:")
            print("   Sistemas de reconhecimento de fala raramente inserem pontuaÃ§Ã£o")
            print("   corretamente ou podem omitir vÃ­rgulas essenciais. Isso causa:")
            print("   â€¢ MudanÃ§a radical no significado das frases")
            print("   â€¢ Dificuldade na anÃ¡lise sintÃ¡tica (parsing)")
            print("   â€¢ Problemas na segmentaÃ§Ã£o de sentenÃ§as")
            print("   â€¢ Ambiguidade na estrutura gramatical")
            print("   â€¢ Falhas em sistemas de QA (Question-Answering)")
            print()
            
            # Verifica se Ã© o caso especÃ­fico "Let's eat grandma"
            is_grandma_case = any("CASO CLÃSSICO" in issue for issue in problems['segmentation']['issues'])
            
            if is_grandma_case:
                print("ðŸš¨ CASO CLÃSSICO DE AMBIGUIDADE DETECTADO!")
                print("â”" * 40)
                print("   ðŸ“š 'Let's eat grandma' vs 'Let's eat, grandma'")
                print()
                print("   SEM vÃ­rgula: 'Let's eat grandma'")
                print("   âž¤ InterpretaÃ§Ã£o: Vamos comer a vovÃ³ (canibalismo!)")
                print()
                print("   COM vÃ­rgula: 'Let's eat, grandma'")
                print("   âž¤ InterpretaÃ§Ã£o: Vamos comer, vovÃ³ (chamando para comer)")
                print()
                print("   ðŸŽ¯ IMPACTO CRÃTICO PARA PLN:")
                print("   â€¢ AnÃ¡lise de dependÃªncia sintÃ¡tica falha completamente")
                print("   â€¢ Sistemas de traduÃ§Ã£o produzem frases incorretas/ofensivas")
                print("   â€¢ ExtraÃ§Ã£o de informaÃ§Ã£o identifica aÃ§Ãµes erradas")
                print("   â€¢ ClassificaÃ§Ã£o de sentimento pode detectar violÃªncia")
                print("   â€¢ Sistemas de diÃ¡logo podem gerar respostas inadequadas")
                print()
                print("   ðŸ’¡ SOLUÃ‡Ã•ES PARA PLN:")
                print("   â€¢ Modelos neurais de pontuaÃ§Ã£o automÃ¡tica")
                print("   â€¢ AnÃ¡lise de pausas e entonaÃ§Ã£o no Ã¡udio original")
                print("   â€¢ CorreÃ§Ã£o gramatical baseada em contexto")
                print("   â€¢ DetecÃ§Ã£o de ambiguidade sintÃ¡tica")
            
            print("ðŸ” PROBLEMAS DE SEGMENTAÃ‡ÃƒO DETECTADOS:")
            for issue in problems['segmentation']['issues']:
                print(f"   âš ï¸  {issue}")
                total_problems += 1
            print()
        
        # PontuaÃ§Ã£o geral com explicaÃ§Ã£o
        if problems['punctuation']['has_problems']:
            print("\nðŸ“ PROBLEMA: AUSÃŠNCIA DE PONTUAÃ‡ÃƒO GERAL")
            print("â”" * 50)
            print("ðŸ“– EXPLICAÃ‡ÃƒO:")
            print("   A falta de pontuaÃ§Ã£o adequada em textos transcritos causa:")
            print("   â€¢ Dificuldade na identificaÃ§Ã£o de fronteiras de sentenÃ§as")
            print("   â€¢ Problemas na anÃ¡lise de estrutura discursiva")
            print("   â€¢ Ambiguidade na interpretaÃ§Ã£o de pausas e Ãªnfases")
            print("   â€¢ Falhas em sistemas de sumarizaÃ§Ã£o automÃ¡tica")
            print()
            print("ðŸ” PROBLEMAS DETECTADOS:")
            for issue in problems['punctuation']['issues']:
                print(f"   âš ï¸  {issue}")
                total_problems += 1
            print()
        
        # Resumo expandido
        print("ðŸ“Š RESUMO DA ANÃLISE")
        print("â”" * 30)
        if total_problems == 0:
            print("âœ… NENHUM PROBLEMA CRÃTICO DETECTADO!")
            print("   O texto estÃ¡ adequado para processamento por sistemas de PLN.")
        else:
            print(f"âš ï¸  {total_problems} PROBLEMA(S) DETECTADO(S)")
            print("   âš¡ RECOMENDAÃ‡Ã•ES PARA PLN:")
            
            if problems['homophones']:
                print("   â€¢ Implementar correÃ§Ã£o contextual de homÃ³fonos")
                print("   â€¢ Usar modelos de linguagem para desambiguaÃ§Ã£o")
                
            if problems['segmentation']['has_problems']:
                print("   â€¢ Aplicar pÃ³s-processamento para inserÃ§Ã£o de pontuaÃ§Ã£o")
                print("   â€¢ Utilizar modelos neurais de pontuaÃ§Ã£o automÃ¡tica")
                print("   â€¢ Implementar anÃ¡lise de pausas no Ã¡udio original")
                
                # RecomendaÃ§Ã£o especÃ­fica para o caso "grandma"
                if any("CASO CLÃSSICO" in issue for issue in problems['segmentation']['issues']):
                    print("   â€¢ âš ï¸ CRÃTICO: Implementar detecÃ§Ã£o de ambiguidade sintÃ¡tica")
                    print("   â€¢ Usar anÃ¡lise de dependÃªncia para validar estruturas")
        
        print(f"\n{'='*60}\n")
    
    def _find_homophones(self, text: str) -> List[Dict]:
        """Detecta homÃ³fonos problemÃ¡ticos"""
        words = re.findall(r'\w+', text.lower())
        found_homophones = []
        
        for word in words:
            if word in self.homophones:
                alternatives = self.homophones[word]
                found_homophones.append({
                    'word': word,
                    'alternatives': alternatives,
                    'context': text
                })
        
        return found_homophones
    
    def _check_segmentation(self, text: str) -> Dict:
        """Verifica problemas de segmentaÃ§Ã£o de palavras"""
        issues = []
        text_lower = text.lower()
        
        # Detectar casos especÃ­ficos famosos
        if re.search(r"let'?s eat \w+", text_lower):
            if "grandma" in text_lower or "gradma" in text_lower:
                issues.append("CASO CLÃSSICO DETECTADO: 'Let's eat grandma' - Ambiguidade crÃ­tica por vÃ­rgula ausente")
        
        # Verificar outros padrÃµes problemÃ¡ticos especÃ­ficos
        for pattern in self.segmentation_patterns:
            if re.search(pattern, text_lower):
                if "eat" in text_lower and "grandma" not in text_lower:
                    issues.append("Frase ambÃ­gua detectada - vÃ­rgula ausente pode mudar sentido drasticamente")
        
        # Palavras muito longas (possÃ­vel junÃ§Ã£o)
        words = text.split()
        long_words = [w for w in words if len(re.sub(r'[^\w]', '', w)) > 15]
        if long_words:
            issues.append(f"Palavras muito longas detectadas: {', '.join(long_words)} (possÃ­vel junÃ§Ã£o incorreta)")
        
        return {
            'issues': issues,
            'has_problems': len(issues) > 0
        }
    
    def _check_punctuation_problems(self, text: str) -> Dict:
        """Verifica problemas gerais de pontuaÃ§Ã£o"""
        issues = []
        
        # Texto sem pontuaÃ§Ã£o final
        if not re.search(r'[.!?]$', text.strip()):
            issues.append("Frase sem pontuaÃ§Ã£o final")
        
        # MÃºltiplas frases sem separaÃ§Ã£o
        if len(text.split()) > 10 and not re.search(r'[.!?,;]', text):
            issues.append("Texto longo sem pontuaÃ§Ã£o interna")
        
        return {
            'issues': issues,
            'has_problems': len(issues) > 0
        }