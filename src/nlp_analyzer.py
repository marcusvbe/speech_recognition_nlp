import re
import nltk
import spacy
from typing import List, Dict
from collections import Counter

# Download necess√°rio para NLTK
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

class NLPAnalyzer:
    """Classe para analisar problemas de PLN em texto transcrito"""
    
    def __init__(self):
        # Carregar modelo do spaCy para ingl√™s
        try:
            self.nlp = spacy.load("en_core_web_sm")
        except OSError:
            print("‚ö†Ô∏è Modelo spaCy n√£o encontrado. Execute: python -m spacy download en_core_web_sm")
            self.nlp = None
        
        # Dicion√°rio de hom√≥fonos comuns em ingl√™s
        self.homophones = {
            'to': ['too', 'two'],
            'too': ['to', 'two'],
            'two': ['to', 'too'],
            'there': ['their', 'they\'re'],
            'their': ['there', 'they\'re'],
            'they\'re': ['there', 'their'],
            'your': ['you\'re'],
            'you\'re': ['your'],
            'its': ['it\'s'],
            'it\'s': ['its'],
            'hear': ['here'],
            'here': ['hear'],
            'write': ['right', 'rite'],
            'right': ['write', 'rite'],
            'rite': ['write', 'right'],
            'new': ['knew'],
            'knew': ['new'],
            'four': ['for', 'fore'],
            'for': ['four', 'fore'],
            'fore': ['four', 'for'],
            'eight': ['ate'],
            'ate': ['eight'],
            'one': ['won'],
            'won': ['one'],
            'sun': ['son'],
            'son': ['sun'],
            'flower': ['flour'],
            'flour': ['flower'],
            'break': ['brake'],
            'brake': ['break'],
            'pears': ['pairs'],
            'pairs': ['pears'],
            'pair': ['pear'],
            'pear': ['pair'],
            'sea': ['see'],
            'see': ['sea'],
            'meat': ['meet'],
            'meet': ['meat'],
            'peace': ['piece'],
            'piece': ['peace'],
            'no': ['know'],
            'know': ['no'],
            'by': ['buy', 'bye'],
            'buy': ['by', 'bye'],
            'bye': ['by', 'buy'],
            'read': ['red'],
            'red': ['read'],
            'tail': ['tale'],
            'tale': ['tail'],
            'mail': ['male'],
            'male': ['mail'],
            'sail': ['sale'],
            'sale': ['sail'],
            'wait': ['weight'],
            'weight': ['wait'],
            'weak': ['week'],
            'week': ['weak'],
            'steel': ['steal'],
            'steal': ['steel'],
            'bear': ['bare'],
            'bare': ['bear'],
            'fair': ['fare'],
            'fare': ['fair']
        }
        
        # Frases problem√°ticas conhecidas para segmenta√ß√£o
        self.segmentation_patterns = [
            r"let'?s eat \w+",
            r"come and eat \w+",
            r"time to eat \w+"
        ]
    
    def analyze_speech_text(self, text: str) -> Dict:
        """Analisa texto de fala para problemas de PLN"""
        problems = {
            'original_text': text,
            'homophones': self._find_homophones(text),
            'punctuation': self._check_punctuation_problems(text),
            'segmentation': self._check_segmentation(text)
        }
        return problems
    
    def display_detailed_analysis(self, problems: Dict):
        """Exibe an√°lise detalhada dos problemas encontrados"""
        text = problems['original_text']
        
        print(f"\n{'='*60}")
        print(f"üìù TEXTO TRANSCRITO: '{text}'")
        print(f"{'='*60}")
        
        total_problems = 0
        
        # Hom√≥fonos com explica√ß√£o expandida
        if problems['homophones']:
            print("\nüîÑ PROBLEMA: AMBIGUIDADE LEXICAL (HOM√ìFONOS)")
            print("‚îÅ" * 50)
            print("üìñ EXPLICA√á√ÉO:")
            print("   Hom√≥fonos s√£o palavras com a mesma pron√∫ncia, mas grafias e")
            print("   significados diferentes. O sistema de reconhecimento de fala pode")
            print("   transcrever a palavra incorreta, alterando completamente o sentido")
            print("   da frase. Este √© um problema cr√≠tico para PLN pois:")
            print("   ‚Ä¢ An√°lise sem√¢ntica fica comprometida")
            print("   ‚Ä¢ Sistemas de tradu√ß√£o podem falhar")
            print("   ‚Ä¢ Classifica√ß√£o de texto produz resultados incorretos")
            print("   ‚Ä¢ An√°lise de sentimento pode ser invertida")
            print()
            print("üîç HOM√ìFONOS DETECTADOS:")
            for h in problems['homophones']:
                print(f"   ‚ö†Ô∏è  Palavra transcrita: '{h['word']}'")
                print(f"   ü§î Poss√≠veis confus√µes: {', '.join(h['alternatives'])}")
                
                # Exemplos espec√≠ficos baseados na palavra
                if h['word'] in ['two', 'to', 'too']:
                    print("   üí° Exemplo de confus√£o:")
                    print("      'I have two apples' vs 'I want to go' vs 'It's too hot'")
                elif h['word'] in ['there', 'their', 'they\'re']:
                    print("   üí° Exemplo de confus√£o:")
                    print("      'There is a book' vs 'Their house' vs 'They're coming'")
                elif h['word'] in ['pairs', 'pears']:
                    print("   üí° Exemplo de confus√£o:")
                    print("      'Two pairs of shoes' vs 'Two pears from tree'")
                print()
                total_problems += 1
        
        # Segmenta√ß√£o com explica√ß√£o expandida
        if problems['segmentation']['has_problems']:
            print("\nüìñ PROBLEMA: ERROS DE SEGMENTA√á√ÉO/PONTUA√á√ÉO")
            print("‚îÅ" * 50)
            print("üìñ EXPLICA√á√ÉO:")
            print("   Sistemas de reconhecimento de fala raramente inserem pontua√ß√£o")
            print("   corretamente ou podem omitir v√≠rgulas essenciais. Isso causa:")
            print("   ‚Ä¢ Mudan√ßa radical no significado das frases")
            print("   ‚Ä¢ Dificuldade na an√°lise sint√°tica (parsing)")
            print("   ‚Ä¢ Problemas na segmenta√ß√£o de senten√ßas")
            print("   ‚Ä¢ Ambiguidade na estrutura gramatical")
            print("   ‚Ä¢ Falhas em sistemas de QA (Question-Answering)")
            print()
            
            # Verifica se √© o caso espec√≠fico "Let's eat grandma"
            is_grandma_case = any("CASO CL√ÅSSICO" in issue for issue in problems['segmentation']['issues'])
            
            if is_grandma_case:
                print("üö® CASO CL√ÅSSICO DE AMBIGUIDADE DETECTADO!")
                print("‚îÅ" * 40)
                print("   üìö 'Let's eat grandma' vs 'Let's eat, grandma'")
                print()
                print("   SEM v√≠rgula: 'Let's eat grandma'")
                print("   ‚û§ Interpreta√ß√£o: Vamos comer a vov√≥ (canibalismo!)")
                print()
                print("   COM v√≠rgula: 'Let's eat, grandma'")
                print("   ‚û§ Interpreta√ß√£o: Vamos comer, vov√≥ (chamando para comer)")
                print()
                print("   üéØ IMPACTO CR√çTICO PARA PLN:")
                print("   ‚Ä¢ An√°lise de depend√™ncia sint√°tica falha completamente")
                print("   ‚Ä¢ Sistemas de tradu√ß√£o produzem frases incorretas/ofensivas")
                print("   ‚Ä¢ Extra√ß√£o de informa√ß√£o identifica a√ß√µes erradas")
                print("   ‚Ä¢ Classifica√ß√£o de sentimento pode detectar viol√™ncia")
                print("   ‚Ä¢ Sistemas de di√°logo podem gerar respostas inadequadas")
                print()
                print("   üí° SOLU√á√ïES PARA PLN:")
                print("   ‚Ä¢ Modelos neurais de pontua√ß√£o autom√°tica")
                print("   ‚Ä¢ An√°lise de pausas e entona√ß√£o no √°udio original")
                print("   ‚Ä¢ Corre√ß√£o gramatical baseada em contexto")
                print("   ‚Ä¢ Detec√ß√£o de ambiguidade sint√°tica")
            
            print("üîç PROBLEMAS DE SEGMENTA√á√ÉO DETECTADOS:")
            for issue in problems['segmentation']['issues']:
                print(f"   ‚ö†Ô∏è  {issue}")
                total_problems += 1
            print()
        
        # Pontua√ß√£o geral com explica√ß√£o
        if problems['punctuation']['has_problems']:
            print("\nüìù PROBLEMA: AUS√äNCIA DE PONTUA√á√ÉO GERAL")
            print("‚îÅ" * 50)
            print("üìñ EXPLICA√á√ÉO:")
            print("   A falta de pontua√ß√£o adequada em textos transcritos causa:")
            print("   ‚Ä¢ Dificuldade na identifica√ß√£o de fronteiras de senten√ßas")
            print("   ‚Ä¢ Problemas na an√°lise de estrutura discursiva")
            print("   ‚Ä¢ Ambiguidade na interpreta√ß√£o de pausas e √™nfases")
            print("   ‚Ä¢ Falhas em sistemas de sumariza√ß√£o autom√°tica")
            print()
            print("üîç PROBLEMAS DETECTADOS:")
            for issue in problems['punctuation']['issues']:
                print(f"   ‚ö†Ô∏è  {issue}")
                total_problems += 1
            print()
        
        # Resumo expandido
        print("üìä RESUMO DA AN√ÅLISE")
        print("‚îÅ" * 30)
        if total_problems == 0:
            print("‚úÖ NENHUM PROBLEMA CR√çTICO DETECTADO!")
            print("   O texto est√° adequado para processamento por sistemas de PLN.")
        else:
            print(f"‚ö†Ô∏è  {total_problems} PROBLEMA(S) DETECTADO(S)")
            print("   ‚ö° RECOMENDA√á√ïES PARA PLN:")
            
            if problems['homophones']:
                print("   ‚Ä¢ Implementar corre√ß√£o contextual de hom√≥fonos")
                print("   ‚Ä¢ Usar modelos de linguagem para desambigua√ß√£o")
                
            if problems['segmentation']['has_problems']:
                print("   ‚Ä¢ Aplicar p√≥s-processamento para inser√ß√£o de pontua√ß√£o")
                print("   ‚Ä¢ Utilizar modelos neurais de pontua√ß√£o autom√°tica")
                print("   ‚Ä¢ Implementar an√°lise de pausas no √°udio original")
                
                # Recomenda√ß√£o espec√≠fica para o caso "grandma"
                if any("CASO CL√ÅSSICO" in issue for issue in problems['segmentation']['issues']):
                    print("   ‚Ä¢ ‚ö†Ô∏è CR√çTICO: Implementar detec√ß√£o de ambiguidade sint√°tica")
                    print("   ‚Ä¢ Usar an√°lise de depend√™ncia para validar estruturas")
        
        print(f"\n{'='*60}\n")
    
    def _find_homophones(self, text: str) -> List[Dict]:
        """Detecta hom√≥fonos problem√°ticos"""
        words = re.findall(r'\w+', text.lower())
        found_homophones = []
        
        for word in words:
            if word in self.homophones:
                alternatives = self.homophones[word]
                found_homophones.append({
                    'word': word,
                    'alternatives': alternatives,
                    'context': text
                })
        
        return found_homophones
    
    def _check_segmentation(self, text: str) -> Dict:
        """Verifica problemas de segmenta√ß√£o de palavras"""
        issues = []
        text_lower = text.lower()
        
        # Detectar casos espec√≠ficos famosos
        if re.search(r"let'?s eat \w+", text_lower):
            if "grandma" in text_lower or "gradma" in text_lower:
                issues.append("CASO CL√ÅSSICO DETECTADO: 'Let's eat grandma' - Ambiguidade cr√≠tica por v√≠rgula ausente")
        
        # Verificar outros padr√µes problem√°ticos espec√≠ficos
        for pattern in self.segmentation_patterns:
            if re.search(pattern, text_lower):
                if "eat" in text_lower and "grandma" not in text_lower:
                    issues.append("Frase amb√≠gua detectada - v√≠rgula ausente pode mudar sentido drasticamente")
        
        # Palavras muito longas (poss√≠vel jun√ß√£o)
        words = text.split()
        long_words = [w for w in words if len(re.sub(r'[^\w]', '', w)) > 15]
        if long_words:
            issues.append(f"Palavras muito longas detectadas: {', '.join(long_words)} (poss√≠vel jun√ß√£o incorreta)")
        
        return {
            'issues': issues,
            'has_problems': len(issues) > 0
        }
    
    def _check_punctuation_problems(self, text: str) -> Dict:
        """Verifica problemas gerais de pontua√ß√£o"""
        issues = []
        
        # Texto sem pontua√ß√£o final
        if not re.search(r'[.!?]$', text.strip()):
            issues.append("Frase sem pontua√ß√£o final")
        
        # M√∫ltiplas frases sem separa√ß√£o
        if len(text.split()) > 10 and not re.search(r'[.!?,;]', text):
            issues.append("Texto longo sem pontua√ß√£o interna")
        
        return {
            'issues': issues,
            'has_problems': len(issues) > 0
        }